{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59316640",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "581371c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 62, 62, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 31, 31, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 30752)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               3936384   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,937,409\n",
      "Trainable params: 3,937,409\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units = 128, activation = 'relu'))\n",
    "model.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8490b897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 142 images belonging to 2 classes.\n",
      "Found 29 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "val_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('Datasets/train',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 8,\n",
    "                                                 class_mode = 'binary')\n",
    "val_set = val_datagen.flow_from_directory('Datasets/val',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 8,\n",
    "                                            class_mode = 'binary')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04b9381d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "10/10 [==============================] - 13s 1s/step - loss: 2.7212 - accuracy: 0.4744 - val_loss: 0.9567 - val_accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 8s 769ms/step - loss: 0.8596 - accuracy: 0.4625 - val_loss: 0.5674 - val_accuracy: 0.6875\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - 15s 2s/step - loss: 0.6727 - accuracy: 0.6026 - val_loss: 0.6713 - val_accuracy: 0.5000\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - 40s 4s/step - loss: 0.6392 - accuracy: 0.7000 - val_loss: 0.6086 - val_accuracy: 0.5625\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - 25s 3s/step - loss: 0.6177 - accuracy: 0.6923 - val_loss: 0.6591 - val_accuracy: 0.4375\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - 5s 509ms/step - loss: 0.5989 - accuracy: 0.7436 - val_loss: 0.5910 - val_accuracy: 0.6875\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - 7s 417ms/step - loss: 0.5804 - accuracy: 0.6795 - val_loss: 0.5107 - val_accuracy: 0.8125\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - 8s 751ms/step - loss: 0.5375 - accuracy: 0.7500 - val_loss: 0.5804 - val_accuracy: 0.6875\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - 9s 927ms/step - loss: 0.4871 - accuracy: 0.7875 - val_loss: 0.6079 - val_accuracy: 0.6250\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.5306 - accuracy: 0.7179 - val_loss: 0.5150 - val_accuracy: 0.6250\n",
      "Epoch 11/50\n",
      "10/10 [==============================] - 7s 693ms/step - loss: 0.5441 - accuracy: 0.7625 - val_loss: 0.5962 - val_accuracy: 0.6250\n",
      "Epoch 12/50\n",
      "10/10 [==============================] - 6s 645ms/step - loss: 0.4733 - accuracy: 0.7625 - val_loss: 0.7227 - val_accuracy: 0.6875\n",
      "Epoch 13/50\n",
      "10/10 [==============================] - 7s 732ms/step - loss: 0.4802 - accuracy: 0.7179 - val_loss: 0.5112 - val_accuracy: 0.7500\n",
      "Epoch 14/50\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.4149 - accuracy: 0.8205 - val_loss: 0.5766 - val_accuracy: 0.6875\n",
      "Epoch 15/50\n",
      "10/10 [==============================] - 7s 678ms/step - loss: 0.3739 - accuracy: 0.8250 - val_loss: 0.4890 - val_accuracy: 0.8125\n",
      "Epoch 16/50\n",
      "10/10 [==============================] - 7s 676ms/step - loss: 0.4936 - accuracy: 0.7625 - val_loss: 0.4099 - val_accuracy: 0.8125\n",
      "Epoch 17/50\n",
      "10/10 [==============================] - 11s 777ms/step - loss: 0.3922 - accuracy: 0.8125 - val_loss: 0.4868 - val_accuracy: 0.8125\n",
      "Epoch 18/50\n",
      "10/10 [==============================] - 9s 629ms/step - loss: 0.4693 - accuracy: 0.7692 - val_loss: 0.6140 - val_accuracy: 0.7500\n",
      "Epoch 19/50\n",
      "10/10 [==============================] - 6s 538ms/step - loss: 0.3995 - accuracy: 0.8077 - val_loss: 0.5639 - val_accuracy: 0.5625\n",
      "Epoch 20/50\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.4136 - accuracy: 0.8125 - val_loss: 0.4608 - val_accuracy: 0.7500\n",
      "Epoch 21/50\n",
      "10/10 [==============================] - 6s 652ms/step - loss: 0.3546 - accuracy: 0.8974 - val_loss: 0.4160 - val_accuracy: 0.8750\n",
      "Epoch 22/50\n",
      "10/10 [==============================] - 9s 667ms/step - loss: 0.3613 - accuracy: 0.8500 - val_loss: 0.5202 - val_accuracy: 0.7500\n",
      "Epoch 23/50\n",
      "10/10 [==============================] - 8s 854ms/step - loss: 0.3443 - accuracy: 0.8846 - val_loss: 0.4418 - val_accuracy: 0.7500\n",
      "Epoch 24/50\n",
      "10/10 [==============================] - 9s 752ms/step - loss: 0.3663 - accuracy: 0.8590 - val_loss: 0.4959 - val_accuracy: 0.8125\n",
      "Epoch 25/50\n",
      "10/10 [==============================] - 9s 876ms/step - loss: 0.3921 - accuracy: 0.8205 - val_loss: 0.4901 - val_accuracy: 0.8125\n",
      "Epoch 26/50\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.3471 - accuracy: 0.8846 - val_loss: 0.5110 - val_accuracy: 0.8125\n",
      "Epoch 27/50\n",
      "10/10 [==============================] - 6s 669ms/step - loss: 0.3137 - accuracy: 0.8846 - val_loss: 0.7186 - val_accuracy: 0.6250\n",
      "Epoch 28/50\n",
      "10/10 [==============================] - 15s 2s/step - loss: 0.3252 - accuracy: 0.8500 - val_loss: 0.5726 - val_accuracy: 0.6875\n",
      "Epoch 29/50\n",
      "10/10 [==============================] - 16s 2s/step - loss: 0.3307 - accuracy: 0.8590 - val_loss: 0.6196 - val_accuracy: 0.7500\n",
      "Epoch 30/50\n",
      "10/10 [==============================] - 10s 794ms/step - loss: 0.2411 - accuracy: 0.9231 - val_loss: 0.3442 - val_accuracy: 0.8750\n",
      "Epoch 31/50\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.2752 - accuracy: 0.8846 - val_loss: 0.4860 - val_accuracy: 0.8125\n",
      "Epoch 32/50\n",
      "10/10 [==============================] - 6s 516ms/step - loss: 0.2431 - accuracy: 0.9103 - val_loss: 0.3965 - val_accuracy: 0.8125\n",
      "Epoch 33/50\n",
      "10/10 [==============================] - 9s 552ms/step - loss: 0.2760 - accuracy: 0.8846 - val_loss: 0.3298 - val_accuracy: 0.8750\n",
      "Epoch 34/50\n",
      "10/10 [==============================] - 8s 873ms/step - loss: 0.2398 - accuracy: 0.9231 - val_loss: 0.6363 - val_accuracy: 0.8125\n",
      "Epoch 35/50\n",
      "10/10 [==============================] - 9s 971ms/step - loss: 0.2550 - accuracy: 0.8974 - val_loss: 0.5109 - val_accuracy: 0.8125\n",
      "Epoch 36/50\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.2882 - accuracy: 0.8590 - val_loss: 0.4160 - val_accuracy: 0.8750\n",
      "Epoch 37/50\n",
      "10/10 [==============================] - 12s 887ms/step - loss: 0.2320 - accuracy: 0.9250 - val_loss: 0.4217 - val_accuracy: 0.7500\n",
      "Epoch 38/50\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.2374 - accuracy: 0.9000 - val_loss: 0.4477 - val_accuracy: 0.6875\n",
      "Epoch 39/50\n",
      "10/10 [==============================] - 4s 354ms/step - loss: 0.2432 - accuracy: 0.9250 - val_loss: 0.2446 - val_accuracy: 0.8750\n",
      "Epoch 40/50\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.2063 - accuracy: 0.9250 - val_loss: 0.4584 - val_accuracy: 0.6875\n",
      "Epoch 41/50\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1822 - accuracy: 0.9615 - val_loss: 0.4769 - val_accuracy: 0.8125\n",
      "Epoch 42/50\n",
      "10/10 [==============================] - 4s 399ms/step - loss: 0.1701 - accuracy: 0.9375 - val_loss: 0.6237 - val_accuracy: 0.7500\n",
      "Epoch 43/50\n",
      "10/10 [==============================] - 9s 922ms/step - loss: 0.1802 - accuracy: 0.9615 - val_loss: 0.6610 - val_accuracy: 0.7500\n",
      "Epoch 44/50\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.2397 - accuracy: 0.9250 - val_loss: 0.3904 - val_accuracy: 0.7500\n",
      "Epoch 45/50\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.1990 - accuracy: 0.9359 - val_loss: 0.5932 - val_accuracy: 0.7500\n",
      "Epoch 46/50\n",
      "10/10 [==============================] - 10s 675ms/step - loss: 0.1348 - accuracy: 0.9487 - val_loss: 0.5310 - val_accuracy: 0.7500\n",
      "Epoch 47/50\n",
      "10/10 [==============================] - 8s 865ms/step - loss: 0.1614 - accuracy: 0.9359 - val_loss: 0.2644 - val_accuracy: 0.9375\n",
      "Epoch 48/50\n",
      "10/10 [==============================] - 9s 925ms/step - loss: 0.1630 - accuracy: 0.9487 - val_loss: 0.5987 - val_accuracy: 0.7500\n",
      "Epoch 49/50\n",
      "10/10 [==============================] - 5s 523ms/step - loss: 0.2017 - accuracy: 0.9125 - val_loss: 0.5764 - val_accuracy: 0.8125\n",
      "Epoch 50/50\n",
      "10/10 [==============================] - 8s 827ms/step - loss: 0.2402 - accuracy: 0.9103 - val_loss: 0.3076 - val_accuracy: 0.8750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x10e9b036970>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.fit(training_set,\n",
    "          steps_per_epoch = 10,\n",
    "          epochs = 50,\n",
    "          validation_data = val_set,\n",
    "          validation_steps = 2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ab225e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce58a82d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "\n",
    "model = model_from_json(loaded_model_json)\n",
    "model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "\n",
    "\n",
    "# Assuming 'model' is already defined somewhere in your code\n",
    "\n",
    "def classify(img_file):\n",
    "    img_name = img_file\n",
    "    test_image = image.load_img(img_name, target_size=(64, 64))\n",
    "\n",
    "    test_image = image.img_to_array(test_image)\n",
    "    test_image = np.expand_dims(test_image, axis=0)\n",
    "    result = model.predict(test_image)\n",
    "\n",
    "    if result[0][0] == 1:\n",
    "        prediction = 'fox'\n",
    "    else:\n",
    "        prediction = 'cat'\n",
    "    print(prediction, img_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7eb981cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 56ms/step\n",
      "cat F:\\Jupyter_Notebook\\AI_INTERNSHIP\\day12\\Code\\Code\\Datasets\\test\\cat\\cat_188.jpeg\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "cat F:\\Jupyter_Notebook\\AI_INTERNSHIP\\day12\\Code\\Code\\Datasets\\test\\cat\\cat_1b5.jpeg\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "cat F:\\Jupyter_Notebook\\AI_INTERNSHIP\\day12\\Code\\Code\\Datasets\\test\\cat\\cat_29c.jpeg\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "cat F:\\Jupyter_Notebook\\AI_INTERNSHIP\\day12\\Code\\Code\\Datasets\\test\\cat\\cat_343.jpeg\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "cat F:\\Jupyter_Notebook\\AI_INTERNSHIP\\day12\\Code\\Code\\Datasets\\test\\cat\\cat_354.jpeg\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "cat F:\\Jupyter_Notebook\\AI_INTERNSHIP\\day12\\Code\\Code\\Datasets\\test\\cat\\cat_367.jpeg\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "cat F:\\Jupyter_Notebook\\AI_INTERNSHIP\\day12\\Code\\Code\\Datasets\\test\\cat\\cat_388.jpeg\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "cat F:\\Jupyter_Notebook\\AI_INTERNSHIP\\day12\\Code\\Code\\Datasets\\test\\cat\\cat_389.jpeg\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "cat F:\\Jupyter_Notebook\\AI_INTERNSHIP\\day12\\Code\\Code\\Datasets\\test\\cat\\cat_8.jpeg\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "fox F:\\Jupyter_Notebook\\AI_INTERNSHIP\\day12\\Code\\Code\\Datasets\\test\\fox\\fox_137.jpeg\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "cat F:\\Jupyter_Notebook\\AI_INTERNSHIP\\day12\\Code\\Code\\Datasets\\test\\fox\\fox_181.jpeg\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "fox F:\\Jupyter_Notebook\\AI_INTERNSHIP\\day12\\Code\\Code\\Datasets\\test\\fox\\fox_189.jpeg\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "fox F:\\Jupyter_Notebook\\AI_INTERNSHIP\\day12\\Code\\Code\\Datasets\\test\\fox\\fox_1e9.jpeg\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "fox F:\\Jupyter_Notebook\\AI_INTERNSHIP\\day12\\Code\\Code\\Datasets\\test\\fox\\fox_238.jpeg\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "fox F:\\Jupyter_Notebook\\AI_INTERNSHIP\\day12\\Code\\Code\\Datasets\\test\\fox\\fox_29f.jpeg\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "fox F:\\Jupyter_Notebook\\AI_INTERNSHIP\\day12\\Code\\Code\\Datasets\\test\\fox\\fox_38d.jpeg\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "fox F:\\Jupyter_Notebook\\AI_INTERNSHIP\\day12\\Code\\Code\\Datasets\\test\\fox\\fox_40.jpeg\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "fox F:\\Jupyter_Notebook\\AI_INTERNSHIP\\day12\\Code\\Code\\Datasets\\test\\fox\\fox_90.jpeg\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "fox F:\\Jupyter_Notebook\\AI_INTERNSHIP\\day12\\Code\\Code\\Datasets\\test\\fox\\fox_e1.jpeg\n"
     ]
    }
   ],
   "source": [
    "# Specify the path to the directory containing images\n",
    "path = 'F:\\\\Jupyter_Notebook\\\\AI_INTERNSHIP\\\\day12\\\\Code\\\\Code\\\\Datasets\\\\test'\n",
    "\n",
    "# List to store file paths\n",
    "files = []\n",
    "\n",
    "# r=root, d=directories, f=files\n",
    "for r, d, f in os.walk(path):\n",
    "    for file in f:\n",
    "        if '.jpeg' in file:\n",
    "            files.append(os.path.join(r, file))\n",
    "\n",
    "# Iterate through the list of image files\n",
    "for f in files:\n",
    "    # Call the classify function for each image file\n",
    "    classify(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad19d2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n",
      "True class: cat, Predicted class: cat, Image path: F:\\Jupyter_Notebook\\AI_INTERNSHIP\\day12\\Code\\Code\\Datasets\\test\\cat\\cat_188.jpeg\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "True class: cat, Predicted class: cat, Image path: F:\\Jupyter_Notebook\\AI_INTERNSHIP\\day12\\Code\\Code\\Datasets\\test\\cat\\cat_1b5.jpeg\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "True class: cat, Predicted class: cat, Image path: F:\\Jupyter_Notebook\\AI_INTERNSHIP\\day12\\Code\\Code\\Datasets\\test\\cat\\cat_29c.jpeg\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "True class: cat, Predicted class: cat, Image path: F:\\Jupyter_Notebook\\AI_INTERNSHIP\\day12\\Code\\Code\\Datasets\\test\\cat\\cat_343.jpeg\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "True class: cat, Predicted class: cat, Image path: F:\\Jupyter_Notebook\\AI_INTERNSHIP\\day12\\Code\\Code\\Datasets\\test\\cat\\cat_354.jpeg\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "True class: cat, Predicted class: cat, Image path: F:\\Jupyter_Notebook\\AI_INTERNSHIP\\day12\\Code\\Code\\Datasets\\test\\cat\\cat_367.jpeg\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True class: cat, Predicted class: cat, Image path: F:\\Jupyter_Notebook\\AI_INTERNSHIP\\day12\\Code\\Code\\Datasets\\test\\cat\\cat_388.jpeg\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "True class: cat, Predicted class: cat, Image path: F:\\Jupyter_Notebook\\AI_INTERNSHIP\\day12\\Code\\Code\\Datasets\\test\\cat\\cat_389.jpeg\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "True class: cat, Predicted class: cat, Image path: F:\\Jupyter_Notebook\\AI_INTERNSHIP\\day12\\Code\\Code\\Datasets\\test\\cat\\cat_8.jpeg\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True class: fox, Predicted class: fox, Image path: F:\\Jupyter_Notebook\\AI_INTERNSHIP\\day12\\Code\\Code\\Datasets\\test\\fox\\fox_137.jpeg\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True class: fox, Predicted class: cat, Image path: F:\\Jupyter_Notebook\\AI_INTERNSHIP\\day12\\Code\\Code\\Datasets\\test\\fox\\fox_181.jpeg\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "True class: fox, Predicted class: fox, Image path: F:\\Jupyter_Notebook\\AI_INTERNSHIP\\day12\\Code\\Code\\Datasets\\test\\fox\\fox_189.jpeg\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "True class: fox, Predicted class: fox, Image path: F:\\Jupyter_Notebook\\AI_INTERNSHIP\\day12\\Code\\Code\\Datasets\\test\\fox\\fox_1e9.jpeg\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "True class: fox, Predicted class: fox, Image path: F:\\Jupyter_Notebook\\AI_INTERNSHIP\\day12\\Code\\Code\\Datasets\\test\\fox\\fox_238.jpeg\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "True class: fox, Predicted class: fox, Image path: F:\\Jupyter_Notebook\\AI_INTERNSHIP\\day12\\Code\\Code\\Datasets\\test\\fox\\fox_29f.jpeg\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "True class: fox, Predicted class: fox, Image path: F:\\Jupyter_Notebook\\AI_INTERNSHIP\\day12\\Code\\Code\\Datasets\\test\\fox\\fox_38d.jpeg\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "True class: fox, Predicted class: fox, Image path: F:\\Jupyter_Notebook\\AI_INTERNSHIP\\day12\\Code\\Code\\Datasets\\test\\fox\\fox_40.jpeg\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "True class: fox, Predicted class: fox, Image path: F:\\Jupyter_Notebook\\AI_INTERNSHIP\\day12\\Code\\Code\\Datasets\\test\\fox\\fox_90.jpeg\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "True class: fox, Predicted class: fox, Image path: F:\\Jupyter_Notebook\\AI_INTERNSHIP\\day12\\Code\\Code\\Datasets\\test\\fox\\fox_e1.jpeg\n",
      "Confusion Matrix:\n",
      "[[9 0]\n",
      " [1 9]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         cat       0.90      1.00      0.95         9\n",
      "         fox       1.00      0.90      0.95        10\n",
      "\n",
      "    accuracy                           0.95        19\n",
      "   macro avg       0.95      0.95      0.95        19\n",
      "weighted avg       0.95      0.95      0.95        19\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Assuming 'model' is already defined somewhere in your code\n",
    "\n",
    "# Lists to store true and predicted labels\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "# Specify the path to the directory containing test images\n",
    "test_path = 'F:\\\\Jupyter_Notebook\\\\AI_INTERNSHIP\\\\day12\\\\Code\\\\Code\\\\Datasets\\\\test'\n",
    "\n",
    "# Iterate through subfolders\n",
    "for class_folder in os.listdir(test_path):\n",
    "    class_path = os.path.join(test_path, class_folder)\n",
    "    \n",
    "    # r=root, d=directories, f=files\n",
    "    for r, d, f in os.walk(class_path):\n",
    "        for file in f:\n",
    "            if '.jpeg' in file:\n",
    "                # Get the true class from the subfolder name\n",
    "                true_class = class_folder\n",
    "                true_labels.append(true_class)\n",
    "\n",
    "                # Call the classify function for each image file\n",
    "                img_path = os.path.join(r, file)\n",
    "                test_image = image.load_img(img_path, target_size=(64, 64))\n",
    "                test_image = image.img_to_array(test_image)\n",
    "                test_image = np.expand_dims(test_image, axis=0)\n",
    "                result = model.predict(test_image)\n",
    "\n",
    "                # Convert the predicted probability to a class label\n",
    "                predicted_class = 'fox' if result[0][0] == 1 else 'cat'\n",
    "                predicted_labels.append(predicted_class)\n",
    "\n",
    "                # Print the prediction\n",
    "                print(f\"True class: {true_class}, Predicted class: {predicted_class}, Image path: {img_path}\")\n",
    "\n",
    "# Create a confusion matrix\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(true_labels, predicted_labels))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1958999f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         cat       0.90      1.00      0.95         9\n",
      "         fox       1.00      0.90      0.95        10\n",
      "\n",
      "    accuracy                           0.95        19\n",
      "   macro avg       0.95      0.95      0.95        19\n",
      "weighted avg       0.95      0.95      0.95        19\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ... (previous code)\n",
    "\n",
    "# Create a confusion matrix\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Plot the confusion matrix using seaborn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['cat', 'fox'], yticklabels=['cat', 'fox'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(true_labels, predicted_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbace952",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
